{
    "caption": "(b) \r\nMulti-hypothesis aggregation.\r\n\r\n",
    "table": [
        "<table id=\"S4.T3.sf2.1.1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S4.T3.sf2.1.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Level</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Method</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\">&#13;\n<span id=\"S4.T3.sf2.1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">MPJPE</span><math id=\"S4.T3.sf2.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T3.sf2.1.1.1.1.1.m1.1a\"><mo mathsize=\"80%\" stretchy=\"false\" id=\"S4.T3.sf2.1.1.1.1.1.m1.1.1\" xref=\"S4.T3.sf2.1.1.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.sf2.1.1.1.1.1.m1.1b\"><ci id=\"S4.T3.sf2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.sf2.1.1.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.sf2.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>&#13;\n</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pose</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">average</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">39.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pose</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">MLPs</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">42.5</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.4.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">joint</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">MLPs</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">41.6</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.5.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pose</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.5.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">reproj.</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.5.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">39.7</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.6.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">joint</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.6.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">reproj.</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.6.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">39.5</span></td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [],
    "references": [
        "We implement two alternatives: predicting the noise 系tsubscriptitalic-系\\epsilon_{t} at each timestep of the reverse process or predicting the original 3D data 0subscript0\\bm{y}_{0}. As shown in Table5a, the latter achieves better results.",
        "Note that the difference between our work and other concurrent diffusion-based methods[22, 18, 14] mainly lies in the regression target. The regression target of our model is the original 3D data 0subscript0\\bm{y}_{0}, while theirs is the noise 系tsubscriptitalic-系\\epsilon_{t} at each timestep. Table5a shows our method outperforms theirs. Further experiments (Table6) reveal that predicting 0subscript0\\bm{y}_{0} yields good performance even in early iterations, while predicting 系tsubscriptitalic-系\\epsilon_{t} does not. This is because in early iterations, when the input tsubscript\\bm{y}_{t} is extremely noisy, it is more effective to predict the original signal 0subscript0\\bm{y}_{0} directly than to obtain 0subscript0\\bm{y}_{0} by predicting the noise 系tsubscriptitalic-系\\epsilon_{t} and then subtracting it from tsubscript\\bm{y}_{t}. This property is valuable for real-time processing. For example, when KK is fixed and computational resources are inadequate, the algorithm is required to produce predictions after the first iteration. Our method of predicting 0subscript0\\bm{y}_{0} still achieves satisfactory results, while theirs of predicting 系tsubscriptitalic-系\\epsilon_{t} does not.",
        "We add the timestep embedding to the network in a similar way as the positional embedding[58]. Table5b shows that adding it to the first layer of the network performs the same as all layers, hence the former is chosen for simplicity. Experimental results demonstrate that timestep embedding is crucial to the denoising process.",
        "Three data augmentation approaches are compared in Table5c, including 1) no augmentation; 2) flipping-once, which flips the input, conducts denoising for KK times, and flips the prediction again. The flipped prediction is then averaged with the unflipped prediction in the original branch to yield the final output; 3) diffusion-flipping, which applies the flip-denoise-flip process to each timestep (KK times). The detailed architectures of these three approaches are shown in Fig.7. Our diffusion-flipping achieves the best results because it averages the 3D poses of the original and flipped branches at each timestep, preventing the accumulation of errors. Other concurrent diffusion-based methods[22, 18, 14] dont use any augmentation or use the flipping-once method. Therefore, our model is more effective than theirs.",
        "As shown in Table5d, we evaluate multiple fusion methods (concatenation, addition, and cross attention[58]) in two fusion types (input fusion and embedding fusion). For embedding fusion, two additional spatio-temporal Transformer layers are used to extract 2D features, after which these features are fused into the denoiser. The best fusion approach is concatenating noisy 3D poses and 2D conditions on the input side, which provides a fast and effective way to modify existing 3D pose estimators to fit the diffusion framework.",
        "Table5e indicates that the best performance can be achieved by setting an appropriate maximum number of timesteps. When TT is too small, we cannot diffuse the ground truth 3D poses to a Gaussian distribution during training, so the denoiser has trouble recovering a clean pose from Gaussian noise during inference. When TT is too large, excessive samples become pure noise after diffusion. Then, the training process of the denoiser is affected and the denoiser cannot generalize well to 3D poses with varying levels of noise (i.e., 3D poses at different timesteps) during inference."
    ]
}