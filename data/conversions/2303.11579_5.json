{
    "table": [
        [
            "Level",
            "Method",
            "MPJPE"
        ],
        [
            "pose",
            "average",
            "39.9"
        ],
        [
            "pose",
            "MLPs",
            "42.5"
        ],
        [
            "joint",
            "MLPs",
            "41.6"
        ],
        [
            "pose",
            "reproj.",
            "39.7"
        ],
        [
            "joint",
            "reproj.",
            "39.5"
        ]
    ],
    "caption": "(b) \r\nMulti-hypothesis aggregation.\r\n\r\n",
    "references": [
        "We implement two alternatives: predicting the noise \u03f5tsubscriptitalic-\u03f5\ud835\udc61\\epsilon_{t} at each timestep of the reverse process or predicting the original 3D data \ud835\udc9a0subscript\ud835\udc9a0\\bm{y}_{0}. As shown in Table\u00a05a, the latter achieves better results.",
        "Note that the difference between our work and other concurrent diffusion-based methods\u00a0[22, 18, 14] mainly lies in the regression target. The regression target of our model is the original 3D data \ud835\udc9a0subscript\ud835\udc9a0\\bm{y}_{0}, while theirs is the noise \u03f5tsubscriptitalic-\u03f5\ud835\udc61\\epsilon_{t} at each timestep. Table\u00a05a shows our method outperforms theirs. Further experiments (Table\u00a06) reveal that predicting \ud835\udc9a0subscript\ud835\udc9a0\\bm{y}_{0} yields good performance even in early iterations, while predicting \u03f5tsubscriptitalic-\u03f5\ud835\udc61\\epsilon_{t} does not. This is because in early iterations, when the input \ud835\udc9atsubscript\ud835\udc9a\ud835\udc61\\bm{y}_{t} is extremely noisy, it is more effective to predict the original signal \ud835\udc9a0subscript\ud835\udc9a0\\bm{y}_{0} directly than to obtain \ud835\udc9a0subscript\ud835\udc9a0\\bm{y}_{0} by predicting the noise \u03f5tsubscriptitalic-\u03f5\ud835\udc61\\epsilon_{t} and then subtracting it from \ud835\udc9atsubscript\ud835\udc9a\ud835\udc61\\bm{y}_{t}. This property is valuable for real-time processing. For example, when K\ud835\udc3eK is fixed and computational resources are inadequate, the algorithm is required to produce predictions after the first iteration. Our method of predicting \ud835\udc9a0subscript\ud835\udc9a0\\bm{y}_{0} still achieves satisfactory results, while theirs of predicting \u03f5tsubscriptitalic-\u03f5\ud835\udc61\\epsilon_{t} does not.",
        "We add the timestep embedding to the network in a similar way as the positional embedding\u00a0[58]. Table\u00a05b shows that adding it to the first layer of the network performs the same as all layers, hence the former is chosen for simplicity. Experimental results demonstrate that timestep embedding is crucial to the denoising process.",
        "Three data augmentation approaches are compared in Table\u00a05c, including 1) no augmentation; 2) flipping-once, which flips the input, conducts denoising for K\ud835\udc3eK times, and flips the prediction again. The flipped prediction is then averaged with the unflipped prediction in the original branch to yield the final output; 3) diffusion-flipping, which applies the flip-denoise-flip process to each timestep (K\ud835\udc3eK times). The detailed architectures of these three approaches are shown in Fig.\u00a07. Our diffusion-flipping achieves the best results because it averages the 3D poses of the original and flipped branches at each timestep, preventing the accumulation of errors. Other concurrent diffusion-based methods\u00a0[22, 18, 14] don\u2019t use any augmentation or use the flipping-once method. Therefore, our model is more effective than theirs.",
        "As shown in Table\u00a05d, we evaluate multiple fusion methods (concatenation, addition, and cross attention\u00a0[58]) in two fusion types (input fusion and embedding fusion). For embedding fusion, two additional spatio-temporal Transformer layers are used to extract 2D features, after which these features are fused into the denoiser. The best fusion approach is concatenating noisy 3D poses and 2D conditions on the input side, which provides a fast and effective way to modify existing 3D pose estimators to fit the diffusion framework.",
        "Table\u00a05e indicates that the best performance can be achieved by setting an appropriate maximum number of timesteps. When T\ud835\udc47T is too small, we cannot diffuse the ground truth 3D poses to a Gaussian distribution during training, so the denoiser has trouble recovering a clean pose from Gaussian noise during inference. When T\ud835\udc47T is too large, excessive samples become pure noise after diffusion. Then, the training process of the denoiser is affected and the denoiser cannot generalize well to 3D poses with varying levels of noise (i.e., 3D poses at different timesteps) during inference."
    ]
}